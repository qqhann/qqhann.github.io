---
title: "04 08 Diary"
date: 2021-04-08T19:07:43+09:00
draft: false
categories:
- Diary
tags:
- Reinforcement Learning
- AtCoder
keywords:
---

# 日記

## 強化学習若手の会　NLPに強化学習を用いるチュートリアル

自然言語処理に強化学習を用いるために知っておくべきことについての勉強会に参加した。

Encoder-decoder系は学習時と推論時で分布が異なるから難しいという話。学習時はteacher forcingを用いるが、推論時はfree running（推論結果が次の入力となること）ため、難易度が異なる。

### REINFORCEというモデル

State s: 文脈情報とトークン

RNNセルの代わりに方策で推論結果を出す？

報酬関数が微分不可能でもいいという利点がある

また、self-criticがよく使われている。

### スライド資料

https://speakerdeck.com/sei88888/2021-dot-04-dot-08-qiang-hua-xue-xi-ruo-shou-falsehui-tiyutoriaru-yan-yu-sheng-cheng-falseqiang-hua-xue-xi

## AtCoderをとく

### ABC195 - A

`H % M ? "No" : "Yes"`というふうに割り切れない場合の処理を先に書くことで`==0`と書かずにすむ。なんかせこいけどすごい。

### ABC195 - C

昨日の学びから、したからカウントアップしていく方が良さそうだという直感は当たっていた。ただ、解析的にやろうとして場合わけと変数を余計に増やしてしまった。

と思っていたが、最速の二人が綺麗すぎただけで別に上位みんながそれにたどり着いたわけではなさそう。

### ABC195 - B

自分の悩みどころで、貪欲法とかの知識が必要なんじゃないかと勘繰ってしまってうまく解けないパターンにハマってしまった。何かのアルゴリズムに落とし込まなければいけないのかなと考えてしまって、AN < 1000W < BNとなるものを考えればいいという数学的変換に考えが行きつかない。

大きい方の数Bで割った係数と余りと、B-Aを使うのかなというアイデアから、突き進んでいた。WAとなるテストケースがあり、原因がわからずじまい。

記憶を消して解き直したい。